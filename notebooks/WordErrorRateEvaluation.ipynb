{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae65c9e",
   "metadata": {},
   "source": [
    "# Calculation of Word Error Rate for Mangled Segment Corrections\n",
    "\n",
    "One of the interesting things to study in more detail is the performance of the OCR text corrections when compared to the text that is visible in the original document. We have set up a small setup to annotate this by annotating mangled segments with highlighting in the original pdf, and an accompanying csv file with the corrected segments, which we can use to calculate the word error rate. To get an idea of the types of mistakes made, we split out the mistakes made by the models as either OCR errors (confusing l for 1, l for i etc.) and hallucination errors, where words are changed to different valid Dutch words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b7407",
   "metadata": {},
   "source": [
    "## Loading in our annotated data\n",
    "\n",
    "We have detected the mangled segments in 10 documents, and manually evaluated the corrections made by three systems: only Tesseract, only ChatGPT, and the combination of Tesseract and ChatGPT. We will load in our dataframes and show some basic analytics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae275ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def collect_annotated_documents(annotation_root_folder: str):\n",
    "    \"\"\"\n",
    "    Helper function to get the names of the annotated files together with their dataframe.\n",
    "    \"\"\"\n",
    "    annotation_files = sorted(glob(os.path.join(annotation_root_folder, '*.csv')))\n",
    "    annotation_dataframe = pd.concat([pd.read_csv(csv_file, sep=';') for csv_file in annotation_files]).fillna(0)\n",
    "    \n",
    "    annotation_dataframe['Number of Hallucinations'] = annotation_dataframe['Number of Hallucinations'].astype(int)\n",
    "    annotation_dataframe['Number of OCR errors'] = annotation_dataframe['Number of OCR errors'].astype(int)\n",
    "    \n",
    "    return annotation_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae946b8d",
   "metadata": {},
   "source": [
    "Next up we load in the dataframes with annotations for all three corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51e1d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseract_dataframe  = collect_annotated_documents('../data/WER_annotation_data/tesseract/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ea86a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Number of Tokens</th>\n",
       "      <th>Number of Mistakes</th>\n",
       "      <th>Number of Hallucinations</th>\n",
       "      <th>Number of OCR errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ministerie\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voedselkwaliteit (hierna: LNV) heeft umet een ...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>krijgen\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adviezen, memo’s en andere documenten \\n</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>verzoek (ongevraagd) verkregen, uitgedaan en/o...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Number of Tokens  \\\n",
       "0                                       ministerie\\n                 1   \n",
       "1  Voedselkwaliteit (hierna: LNV) heeft umet een ...                18   \n",
       "2                                          krijgen\\n                 1   \n",
       "3           adviezen, memo’s en andere documenten \\n                 5   \n",
       "4  verzoek (ongevraagd) verkregen, uitgedaan en/o...                22   \n",
       "\n",
       "   Number of Mistakes  Number of Hallucinations  Number of OCR errors  \n",
       "0                   0                         0                     0  \n",
       "1                   2                         0                     2  \n",
       "2                   0                         0                     0  \n",
       "3                   0                         0                     0  \n",
       "4                   0                         0                     0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesseract_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4c3cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_dataframe  = collect_annotated_documents('../data/WER_annotation_data/chatgpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a4eb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_dataframe  = collect_annotated_documents('../data/WER_annotation_data/tesseract+chatgpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb6716",
   "metadata": {},
   "source": [
    "Now let's look at the total size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5142026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The annotated dataset contains 227 mangled segments, totalling 672 mangled tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"The annotated dataset contains %d mangled segments, totalling %d mangled tokens\" % (tesseract_dataframe.shape[0], tesseract_dataframe['Number of Tokens'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656ee19",
   "metadata": {},
   "source": [
    "## Calculating WER for the different corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26620f",
   "metadata": {},
   "source": [
    "Now that we have these dataframes, we can calculate the WER by summing the total number of mistake and dividing by the total number of tokens. We will print this for all three of the correction strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd8a08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER(annotation_dataframe: pd.DataFrame):\n",
    "    # WER is just the number of corect tokens divided by the number of mistakes in our case\n",
    "    # note that in principle this score can exceed 0\n",
    "    return annotation_dataframe['Number of Mistakes'].sum() / annotation_dataframe['Number of Tokens'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9856b0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10714285714285714"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only chatgpt\n",
    "calculate_WER(chatgpt_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73a8caf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06547619047619048"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only tesseract\n",
    "calculate_WER(tesseract_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01e1d24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02976190476190476"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The combination of both\n",
    "calculate_WER(combination_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55343d26",
   "metadata": {},
   "source": [
    "When looking at the WER of the different correction strategies we can see that the ChatGPT model has the highest word error rate, and that the combination of both ChatGPT and Tesseract has the lowest number WER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc68d1",
   "metadata": {},
   "source": [
    "## Number of Hallucinations\n",
    "\n",
    "To investigate the differences in the Word Error Rate for the different strategies we will look at the number and percentages of hallucinations Vs. OCR mistakes for all of the three strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "282353fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First for Tesseract\n",
    "tesseract_dataframe['Number of Hallucinations'].sum().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "550bdfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now for ChatGPT\n",
    "chatgpt_dataframe['Number of Hallucinations'].sum().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38d72ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also print the percentage for chatgpt of hallucinations\n",
    "# percentage for chatgpt\n",
    "chatgpt_dataframe['Number of Hallucinations'].sum().astype(int) / chatgpt_dataframe['Number of Mistakes'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be063b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now for the combination\n",
    "combination_dataframe['Number of Hallucinations'].sum().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c29d3778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now also the percentage for the combination\n",
    "combination_dataframe['Number of Hallucinations'].sum().astype(int) / combination_dataframe['Number of Mistakes'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef769cec",
   "metadata": {},
   "source": [
    "We can see that Tesseract only makes OCR type errors, with ChatGPT making an equal amount of hallucinations and OCR mistakes. We can see that although the percentage of errors that is a hallucination goes up in the combination, the absolute number is actually reduced drastically, from 36 to 12, so the number of hallucinations is reduced by two thirds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_redaction_env",
   "language": "python",
   "name": "text_redaction_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
